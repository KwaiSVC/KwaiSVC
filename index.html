<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<!-- saved from url=(0043)http://www-personal.umich.edu/~ywchao/hico/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Search-oriented Micro-video Captioning</title>
    <link rel="stylesheet" href="assets/css/styles.css" />
</head>

<body>

<table border="0" width="1000px" align="center">
<tbody><tr>
<td>

<!-- Title -->
<!-- <center>
<h1>
<font face="helvetica" style="font-size:87%">
    Search-oriented Micro-video Captioning
</font>
</h1>
</center> -->

<br>

<!-- Figure -->
<center>
<img src="./CSAN/figs/kwaiSVC-BG.jpg" height="400">
</center>

<!-- Abstract -->
<center>
<h2><font face="helvetica" style="font-size:24px">Abstract</font></h2>
<hr style="margin-top:-10px; margin-bottom:13px">
</center>


<font face="helvetica" style="font-size:15px">
<div style= "text-indent:25px; text-align:justify">
    Pioneer efforts have been dedicated to the content-oriented video
captioning that generates relevant sentences to describe the visual
contents of a given video from the producer perspective. By contrast,
this work targets at the search-oriented one that summarizes
the given video via generating query-like sentences from the consumer
angle. Beyond relevance, diversity is vital in characterizing
consumers’ seeking intention from different aspects. Towards this
end, we devise a large-scale multimodal pre-training network regularized
by five tasks to strengthen the downstream video representation,
which is well-trained over our collected 11M micro-videos.
Thereafter, we present a flow-based diverse captioning model to
generate different captions from consumers’ search demand. This
model is optimized via a reconstruction loss and a KL divergence
between the prior and the posterior. We justify our model over our
constructed golden dataset comprising 690k &ltquery, micro-video&gt
pairs and experimental results demonstrate its superiority.
</div>

<!-- Code -->
<center>
<h2><font face="helvetica" style="font-size:24px">Code</font></h2>
<hr style="margin-top:-10px; margin-bottom:13px">
</center>


<font face="helvetica" style="font-size:15px">
<div>    
    <a href="" style="text-decoration: none;">
    <img src="./CSAN/figs/download_button.jpg" height="30px">
    </a>
    <div style="margin-left: 10px; margin-top: 1px; display: inline-block;">
        <a href="https://pan.baidu.com/s/1S7WBzPlmpYpdQC0t9zhQtw?pwd=v5r4">Baidu Cloud</a> (password: v5r4) 
        &nbsp
        <a href="https://drive.google.com/drive/folders/1mifiCH-rXedrq3ZdnyMbBO01nlOwT9z1?usp=sharing">Google Drive</a>
        <br>
        Code of our project. It contains our pretraining model (MEEK), diverse captioning model (FLIP), and baseline models.
    </div>
</div>

<br>

<!-- Dataset -->
<center>
<h2><font face="helvetica" style="font-size:24px">Dataset</font></h2>
<hr style="margin-top:-10px; margin-bottom:13px">
</center>


<font face="helvetica" style="font-size:15px">
<div>
    <h2><font face="helvetica" style="font-size:20px">KwaiSVC-222k</font></h2>

    <a href="" style="text-decoration: none;">
    <img src="./CSAN/figs/download_button.jpg" height="30px">
    </a>
    <div style="margin-left: 10px; margin-top: 1px; display: inline-block;">
        <a href="https://pan.baidu.com/s/1v6x14o5K9IuM3A-IS29UoA?pwd=ihc2">Baidu Cloud</a> (password: ihc2)
<!--         &nbsp
        <a href=" ">Google Drive</a> -->
        <br>
        Golden dataset for divrse captioning. It contains video-query pairs, extracted video and text features, and checkpoints of MEEK and FLIP.
    </div>
</div>

<br>

<div>
    <h2><font face="helvetica" style="font-size:20px">KwaiSVC-11M </font></h2>

<!--     <a href="" style="text-decoration: none;">
    <img src="./CSAN/figs/download_button.jpg" height="30px">
    </a> -->
    <div style="margin-left: 1px; margin-top: 1px; display: inline-block;">
<!--     <a href=" ">Baidu Cloud</a> 
    &nbsp
    <a href=" ">Google Drive</a>
    <br> -->
        Dataset for multimodal video representation learning. This dataset will be provided by request.	
    </div>
</div>

<br>

<!-- Last Update
<hr>
<font face="helvetica" style="font-size:15px">Last updated on 10/6/2022</font>
</td>
</tr>
-->

</tbody></table></body></html>


